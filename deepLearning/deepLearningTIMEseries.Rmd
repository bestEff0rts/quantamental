---
title: "Untitled"
output: github_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(ISLR2)
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
install.packages("keras")
keras::install_keras(method = "conda", python_version = "3.10")
```

## time series prediction

#1 - нужно настроить данные и стандартизировать каждую из переменных

```{r}
xdata <-data.matrix(NYSE[, c("DJ_return", "log_volume","log_volatility")])
istrain <- NYSE[, "train"]
xdata <-scale(xdata)
# fix(istrain)
# fix(xdata)
```

переменная istrain содержит значение TRUE для каждого года в обучающем
наборе и значение FALSE для каждого года в тестовом наборе

```{r}
lagfunc <- function(x, k = 1) {
 n <-nrow(x)
 pad <-matrix(NA, k, ncol(x))
 rbind(pad, x[1:(n- k), ])
 }
```

функции для создания lagged версий трех временных рядов. и датафрейм для
них

```{r}
arframe <-data.frame(log_volume = xdata[, "log_volume"],
 L1 = lagfunc(xdata, 1), L2 = lagfunc(xdata, 2),
 L3 = lagfunc(xdata, 3), L4 = lagfunc(xdata, 4),
 L5 = lagfunc(xdata, 5)
 )
arframe <- arframe[-(1:5), ]
istrain <- istrain[-(1:5)]
# fix(istrain)
# fix(arframe)
```

#Обучаем линейную AR-модель на train data с помощью lm() и прогнозируем
на основе тестовых данных.

```{r}
 arfit <-lm(log_volume ~., data = arframe[istrain, ])
 arpred <-predict(arfit, arframe[!istrain, ])
 V0 <-var(arframe[!istrain, "log_volume"])
 1-mean((arpred- arframe[!istrain, "log_volume"])^2) / V0
```

теперь обучаем включая фактор day_of_week.

```{r}
arframed <-data.frame(day = NYSE[-(1:5), "day_of_week"], arframe)
arfitd <-lm(log_volume ~ ., data = arframed[istrain, ])
arpredd <-predict(arfitd, arframed[!istrain, ])
1-mean((arpredd- arframe[!istrain, "log_volume"])^2) / V0
```

чтобы обучить RNN, нужно изменить форму этих данных, т к ожидается
последовательность из L =5 векторов характеристик X = {x ∈}L 1 для
каждого наблюдения. Это lagged версии временных рядов

```{r}
 n <-nrow(arframe)
 xrnn <-data.matrix(arframe[,-1])
 xrnn <-array(xrnn, c(n, 3, 5))
 xrnn <- xrnn[,, 5:1]
 xrnn <-aperm(xrnn, c(1, 3, 2))
 dim(xrnn)
```

4 этапа: 1-тизвлечь матрицу n×15 с lagged версиями трех
переменных-предикторов из arframe. 2- преобразовать эту матрицу в массив
n×3×5, изменив атрибут dimension, поскольку новый массив заполняется по
столбцам. 3- изменение порядка lagged переменных, так что индекс 1
находится дальше всего по времени, а индекс 5 ближе всего. 4- координаты
массива перестраиваются (например, при частичном преобразовании) в
формат, ожидаемый модулем RNN в keras.

```{r message=FALSE, warning=FALSE}
library(keras)
library(reticulate)
library(magrittr)
 model <- keras_model_sequential() %>%
 layer_simple_rnn(units = 12,
 input_shape = list(5, 3),
 dropout = 0.1, recurrent_dropout = 0.1) %>%
 layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
 loss = "mse")
```

```{r}
history <-model %>% fit(
 xrnn[istrain,, ], arframe[istrain, "log_volume"],
 batch_size = 64, epochs = 200,
 validation_data =
 list(xrnn[!istrain,, ], arframe[!istrain, "log_volume"])
 )
kpred <-predict(model, xrnn[!istrain,, ])
 1-mean((kpred- arframe[!istrain, "log_volume"])^2) / V0
```

Обучение этой модели занимает около одной минуты. Можно заменить
приведенную выше команду keras_model_sequential() командой:

```{r}
 model <- keras_model_sequential() %>%
 layer_flatten(input_shape = c(5, 3)) %>%
 layer_dense(units = 1)
```

Здесь функция layer_flatten() просто берет входную последовательность и
преобразует ее в длинный вектор предикторов. В результате получается
линейная AR-модель. Чтобы соответствовать нелинейной AR-модели, нужно
добавить hidden layer.

```{r}
x <-model.matrix(log_volume ~.- 1, data = arframed)
colnames(x)
```

Однако, поскольку уже есть матрица lagged переменных из ARmodel, которую
обучили ранее с помощью команды lm(), можно обучить нелинейную AR-модель
без необходимости выполнять сглаживание. Извлекаем модельную матрицу x
из arframed, которая включает переменную day_of_week. (-1 - no
intercept)

```{r}
 arnnd <-keras_model_sequential() %>%
 layer_dense(units = 32, activation = 'relu',
 input_shape = ncol(x)) %>%
 layer_dropout(rate = 0.5) %>%
 layer_dense(units = 1)
arnnd %>% compile(loss = "mse",
 optimizer = optimizer_rmsprop())
history <- arnnd %>% fit(
 x[istrain, ], arframe[istrain, "log_volume"], epochs = 100,
 batch_size = 32, validation_data =
 list(x[!istrain, ], arframe[!istrain, "log_volume"])
 )
plot(history)
npred <-predict(arnnd, x[!istrain, ])
1-mean((arframe[!istrain, "log_volume"]- npred)^2) / V0
```

Переменная day_of_week является пятиуровневым фактором (существует пять
торговых дней), и значение-1 приводит к появлению пяти, а не четырех
фиктивных переменных.(избежать dummy trap)\
activation function- ReLU (Rectified Linear Unit)
