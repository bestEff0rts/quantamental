---
title: "Subset Selection(Best Subset Selection, Forward/Backward Stepwise Selection); Choosing optimal model(test error rate)- Adjusting training error(Cp,AIC,BIC,adjusted R^2) and DIRECTLY estimating test error- Validation and CV"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## Best Subset Selection

Пример как прогнозировать зарплату бейсболиста на основе различных статистических данных- с показателями за предыдущий год. sum(is.na(Hitters\$Salary))- сколько salary пропущенно

```{r}
library(ISLR)
fix(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))

```

Функция na.omit() удаляет все строки, в которых отсутствуют значения любой переменной.

```{r}
Hitters<- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
```

#Best subset selection
           1[Идентифицирует subset of P предикторов, которые мы полагаем влияют на response]-->
2[Обучает модель с помощью МНК=Least Squares на reduced set of variables]
           ")

Функция regsubsets() (из библиотеки leaps) выполняет best subset selection sub-regsubsets() устанавливает выбор, определяя лучшую модель, которая содержит заданное число из предсказателей, где лучше всего количественно с помощью RSS.

```{r}
library(leaps)
bsubssel.fit<-regsubsets(Salary~.,Hitters)
summary(bsubssel.fit)
```

## Интерпретация
Звездочка указывает на то, что данная переменная включена в соответствующую
модель. Например, этот вывод показывает, что лучшая двухпеременная модель
 содержит только Hits и CRBI.
По умолчанию, regsubsets() сообщает только результаты
 до лучшей восьми-переменной модели.
 Но  nvmax может быть использована, чтобы вернуть так много переменных, как указано.Например:
```{r}
bsubssel.fit<-regsubsets(Salary~.,data=Hitters, nvmax=19)
bss.summary<-summary(bsubssel.fit)
```
Names(summary) показывает AIC(Cp), BIC, RSS, $R^2$, $R^2 adjusted=1-/(1-R^2)(n-1)/(n-k-1))$ (используется при более чем одном предикторе, добавляя penalty за усложнение модели)

```{r cars}
names(bss.summary)
bss.summary$rsq
```

```{r}
which.max(bss.summary$adjr2)
# points(11, bss.summary$adjr2[11], col="red", cex=2, pch=20)
which.min(bss.summary$cp)
# points(10,bss.summary$cp[10],col="red",cex=2,pch=20)
which.min(bss.summary$bic)
# plot(bss.summary$bic,xlab="Number of Variables",ylab="BIC")
# points(6,bss.summary$bic[6],col="red",cex=2,pch=20)
```
## plot(bsubssel.fit, scale="")
Команда points() работает так же, как команда plot(), но добавляет точки на уже созданный график.

Функция regsubsets() имеет встроенную команду plot(), которая может будет использоваться для отображения выбранных переменных для лучшей модели с заданным числом предикторов (в примере nvmax=19), ранжированных по BIC,Cp, adjusted $R^2$, или AIC.


```{r}
plot(bsubssel.fit,scale="r2")
plot(bsubssel.fit,scale="adjr2")
plot(bsubssel.fit,scale="Cp")
plot(bsubssel.fit,scale="bic")
?plot.regsubsets.

```
## Интерпретация
 Верхняя строка каждого графика содержит черный квадрат для каждой выбранной переменной в соответствии с оптимальной моделью, связанной с этой статистикой. Так,мы видим, что несколько моделей имеют BIC около 150

```{r}
coef(bsubssel.fit,6)
bsubssel.fit6<-regsubsets(Salary~.,data=Hitters, nvmax=6)
summary(bsubssel.fit6)
```
Однако, модель с наименьшим BIC - это шести-переменная модель, которая содержит только AtBat,Hits,Walks,CRBI,DivisionW,and PutOuts.

## Forward and Backward Stepwise Selection

1[FORWARD STEPWISE SELECTION Mo- null model no predictors]-->
           
2[For k=0..p-1 ]-->

2.1(Consider all p-k model that augment predictors in Mk with 1 additional predictor)-->

2.2(Choose best=lowest RSS or highest R^2 and call it Mk+1)-->

3[Select a 1 best model among M0,..Mp using AIC, BIC, CV prediction error, adj R^2]


## regsubsets()
function to perform forward stepwise or backward stepwise selection, using the argument method="forward"or method="backward"
```{r}
fwd.reg.fit<- regsubsets(Salary~., data=Hitters,nvmax=19, method="forward")
summary(fwd.reg.fit)

bwd.reg.fit<- regsubsets(Salary~., data=Hitters, nvmax=19, method="backward")
summary(bwd.reg.fit)
```
## Интерпретация
Например, для bwd лучшая модель с 1 предиктором включает только CHmRun.
However,the best seven-variable models identified by forward stepwise selection,backward stepwise selection,and best subset selection are different.
Коэффициенты для лучшей модели с 7 предикторами
```{r}
coef(bsubssel.fit,7)
coef(fwd.reg.fit,7)
coef(bwd.reg.fit,7)
```
##Choosing Among Models Using the Validation Set Approach and Cross-Validation

Создаем вектор элементы которого= true если соответствующие
 наблюдение входит в train set, а ЛОЖНОЕ - в противном случае.
 $!$ приводит к переключению TRUE на FALSE и vice versa
```{r}
set.seed(1)
v.train=sample(c(TRUE,FALSE), nrow(Hitters), rep=TRUE)
v.test=(!v.train)
```
Теперь мы применяем regsubsets() к training set to perform best subset selection
#expression Hitters[train,].
 we subset the Hitters data frame directly to access only the training subset of the data, using the expression $Hitters[train,]$.
```{r}
rgfit.best<-regsubsets(Salary~., data=Hitters[v.train,], nvmax=19)

```

now compute the validation set error for the best
 model of each model size. 
 We first make a model matrix from the test data
```{r}
test.mtrx<-model.matrix(Salary~. ,data=Hitters[v.test,])
val.err<-rep(NA,19)
for (i in 19) {
  coeff=coef(rgfit.best,id=i)
  pred=test.mtrx[,names(coeff)]%*%coeff
  val.err[i]=mean((Hitters$Salary[v.test]-pred)^2)
}
val.err
```
 
```{r}
set.seed(1)
 train=sample(c(TRUE,FALSE), nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],
 nvmax=19)
test.mat=model.matrix(Salary~.,data=Hitters[test,])
 val.errors=rep(NA,19)
  for(i in 1:19){
     coefi=coef(regfit.best,id=i)
 pred=test.mat[,names(coefi)]%*%coefi
  val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
  }
 val.errors
 which.min(val.errors)
 coef(regfit.best,7)
```

## Function как predict() для regsubsets()
```{r}
predict.regsubsets=function(object,newdata,id,...){
 form=as.formula(object$call[[2]])
 mat=model.matrix(form,newdata)
 coefi=coef(object,id=id)
 xvars=names(coefi)
 mat[,xvars]%*%coefi
 }
```

  Finally,we perform best subset selection on the full dataset,and 
  select the best ten-variable model(full datset to obtain more accurate coefficient estimates)
  Note that we perform best subset selection on the full dataset and select the best ten variable model, rather than simply using the variables that were obtained from the training set, because the best ten-variable model on the full data   
 set may differ from the corresponding model on the training set.
 
```{r}
regfit.best=regsubsets(Salary~.,data=Hitters,nvmax=19)
coef(regfit.best,10)
```
#Интерпретация

##choosing among the models of different sizes using CV
=perform best subset selection within each of the k training sets
```{r}
k=10
set.seed(1)
folds=sample(1:k,nrow(Hitters),replace=TRUE)
cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))
```
# loop that performs cross-validation

```{r}
for(j in 1:k){
 best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,],
 nvmax=19)
 for(i in 1:19){
 pred=predict(best.fit,Hitters[folds==j,],id=i)
 cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2)
 }
 }
```
This has given us a 10×19 matrix, of which the (i,j)th element corresponds
 to the test MSE for the ith cross-validation fold for the best j-variable
 model. We use the apply() function to average over the columns of this apply()
 matrix in order to obtain a vector for which the jth element is the cross
validation error for the j-variable model.
```{r}
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors

plot(mean.cv.errors,type='b')
```

CV выбирает 10-variable model. We now perform best subset selection on the full data set in order to obtain the 11-variable model.
```{r}
 reg.best=regsubsets(Salary~.,data=Hitters, nvmax=19)
 coef(reg.best,11)
```

 