---
title: "Support Vector Machines"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(e1071)
library(ISLR)
```

## Fit SVM for a given value of cost

#demonstration: svm()
 use of this function on a two-dimensional example so that we can plot the resulting
 decision boundary. We begin by generating the observations, which belong
 to two classes, and checking whether the classes are linearly separable.
```{r}
set.seed(1)
x= matrix(rnorm(20*2), ncol=2)
y=c(rep(-1,10),rep(1,10))
x[y==1,]=x[y==1,] +1
plot(x, col=(3-y))

```
Classes are not lineary separable

#Fit SVM
```{r}
data=data.frame(x=x,y=as.factor(y))
library(e1071)
svm.fit=svm(y~.,data=data, kernal="linear", cost=10, scale=FALSE)
plot(svm.fit, data)
```

 for the svm() function to perform classification (as opposed to SVM-based
 regression), we must encode the response as a factor variable. We now
 create a data frame with the response coded as a factor
 
 The argument scale=FALSE tells the svm() function not to scale each feature
 to have mean zero or standard deviation one; depending on the application,
 one might prefer to use scale=TRUE.
 
 the second feature is plotted on the
 x-axis and the first feature is plotted on the y-axis,in contrast to the behavior of
 the usual plot() function in R.
 The support vectors are plotted as crosses
 and the remaining observations are plotted as circles; we see here that there
 are seven support vectors. We can determine their identities
```{r}
svm.fit$index
summary(svm.fit)
```
#summary()
a linear kernel was used with cost=10,and there were 10 support vectors, 6 in one class and 4 in the other.
```{r}
svm.fit2=svm(y~.,data=data,cost=0.1, kernel="linear", scale=FALSE)
plot(svm.fit2,data)
```
***Smaller value of cost-> wider margin (шире)-> more support vectors***

#tune() for CV
```{r}
set.seed(1)
tune.cv=tune(svm, y~.,data=data, kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary(tune.cv)
```

 By default, tune() performs ten-fold cross-validation. 
 compare SVMs with a linear
 kernel,using a range of values of the cost parameter.
 
# best model?
```{r}
best.mod=tune.cv$best.model
summary(tune.cv$best.model)
```

cost=0.1 results in the lowest cross-validation error rate.The
 tune() function stores the best model obtained
 
# predict()
```{r}
x.test=matrix(rnorm(20*2), ncol=2)
y.test=sample(c(-1,1),20, rep=TRUE)
x.test[y.test==1,]=x.test[y.test==1,] + 1
test.dat=data.frame(x=x.test, y=as.factor(y.test))
```

predict the class label on a set of test observations,at any given value of the cost parameter
#predict class labels on generated test data, using best model from cv
```{r}
y.predicted=predict(best.mod,test.dat)
table(predict=y.predicted, true=test.dat$y)
summary(best.mod)
```
#интерпретация
при cost=0.1, 9+8= 17 правильно классифицированы
```{r}
# library(pROC)
# roc1=roc(y~.,data=test.dat ,auc=TRUE)
```

#twoclassesarelinearlyseparable
```{r}
 x[y==1,]=x[y==1,]+0.5
 plot(x, col=(y+5)/2, pch=19)
```
barely linearly separable.
We fit the support vector classifier and plot the resulting hyperplane, using a very large value of costs (no observations are misclassified)
```{r}
dat=data.frame(x=x,y=as.factor(y))
svm.fit3=svm(y~.,data=dat, kernel="linear", cost=1e5)
summary(svm.fit3)
plot(svm.fit3,dat)
```
#int
 No training errors and only 3 support vectors.
 However,the margin is very narrow
 **большое значение cost-> узкая(narrow) margin-> меньшеее кол-во support vectors**
 (because
 the observations that are not support vectors, indicated as circles,are very  close to the decision boundary). It seems likely that this model will perform
 poorly on test data. 
 *overfit= small bias, lots of variance*
```{r}
svm.fit4=svm(y~., data=dat,kernel="linear", cost= 1)
summary(svm.fit4)
plot(svm.fit4, dat)
```
#int
1 misclassification, however  we also obtain
 a much wider margin and make use of seven support vectors. It seems
 likely that this model will perform better on test data
*trade-off- little bias in for a significant reduction in variance* 

## Support Vector Machine (non-linear kernel)

generate data with a non-linear class boundary
```{r}
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+3
x[101:150,]=x[101:150,]-3
y=c(rep(1,150),rep(2,50))
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
```
The data is randomly split into training and testing groups. 
Radial Kernel $E^-\gamma*(a-b)^2$
$\gamma=1$

```{r}
train=sample(200,100)
svm.nl.fit=svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1)
plot(svm.nl.fit, dat[train,])
```
#int
SVM has a non-linear boundary.
```{r}
summary(svm.nl.fit)
```
#int
**bias variance flexibility trade-off**
We can see from the figure that there are a fair number of training errors
 in this SVM fit.
*increase the value of cost-> reduce num of training errors(margin narrow-узкая) but risk of overfitting*;
this comes at the price of a more irregular decision boundary (high variance) that seems to be at risk of overfitting the data.

#cost= 1e5(huge)
```{r}
svm.nl.fit2=svm(y~., data=dat[train,], kernel="radial",gamma=1,cost=1e5)
plot(svm.nl.fit2, dat[train,])

```
#tune() = Cross Validation for Radial Kernel's parameters
to find best $\gamma$ and $cost$
```{r}
set.seed(1)
tune.nl.cv=tune(svm, y~., data=dat[train,], kernel="radial", ranges=list(cost=c(0.1,1,10,100,1000),  gamma=c(0.1,0.2,0.3,0.4,0.5,1,2,3,4,6,7,8,9,10)))
summary(tune.nl.cv)
```
*best parameters* cost=1, $\gamma=0.5$
## predict()
```{r}
table(true=dat[-train,"y"], pred=predict(tune.nl.cv$best.model,
 newdata=dat[-train,]))
```

We can view the test set predictions for this model by applying the predict()
 function to the **test data: *newdata==dat[-train,]* (index set)**
#int
правильно классифицированны = из 

##ROC Curves
```{r}
library(ROCR)
rocplot=function(pred, truth, ...){
 predob = prediction(pred, truth)
 perf = performance(predob, "tpr", "fpr")
 plot(perf,...)}
```
write a short function to plot an ROC curve
*given a vector containing a numerical score for each observation, pred*
and
 *a vector containing the class label for each observation, truth.*
```{r}

```
#note
SVMs and support vector classifiers *output class labels for each observation.*
However, it is also possible to obtain *fitted values for each observation*
=numerical scores used to obtain the class labels. 

 the sign of the fitted value determines
 on which *side of the decision boundary* the observation lies. 
 
 **relationship between the fitted value and the class prediction** for a given
 observation =
 if the fitted value > zero-> the observation is assigned to one class, 
 and 
 if it is < zero-> it is assigned to the other. 
```{r}
svm.fit.opt=svm(y~., data=dat[train,], kernel="radial", cost=10, gamma=0.1, decision.values=T)
fitted=attributes(predict(svm.fit.opt,dat[train,],decision.values=TRUE))$decision.values
```
 In order to obtain the fitted values for a given SVM model fit, we
 use decision.values=TRUE when fitting svm(). Then the predict() function
 will output the fitted values
# ROC curve
```{r}

rocplot(fitted,dat[-train,"y"])
```
