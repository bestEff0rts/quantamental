---
title: "unsupervisedLearning: PCA"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r}
states=row.names(USArrests)
states
names(USArrests)
apply(USArrests, 2, mean)
```
apply() function allows us to apply a function—in this case,
 the mean() function—to each row or column of the data set. The second
 input here denotes whether we wish to compute the mean of the rows, 1,
 or the columns, 2. 
```{r}
apply(USArrests, 2, var)
```
 *pca* 
```{r}
pca=prcomp(USArrests, scale=TRUE)
names(pca)
```

By default, the prcomp() function centers the variables to have mean zero.
 By using the option scale=TRUE, we scale the variables to have standard
 deviation one.
```{r}
pca$center
pca$scale
pca$rotation
```
The center and scale components correspond to the means and standard
 deviations of the variables that were used for scaling prior to implementing
 PCA.
 The rotation matrix provides the principal component loadings; each col
umn of pr.out$rotation contains the corresponding principal component
 loading vector
*plot pc1 and pc2*
```{r}
biplot(pca, scale=0)
```
biplots unique up to a sign
```{r}
pca$rotation=-pca$rotation
pca$x=-pca$x
biplot(pca, scale=0)
```
*variance explained by each pc*
```{r}
pca$sdev
pca.var=pca$sdev^2
pca.var
```
*PVE* 
```{r}
pve=pca.var/sum(pca.var)
pve
```
proportion of variance explained by each principal component= variance explained by each pc\ the total variance explained by all pc
*plot*
```{r pve plot}
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained",ylim=c(0,1), type='b')
```
(функция cumsum()вычисляет cumulative sum элементов числового вектора)
Наглядно представлено, что PC1- первый основной компонент- объясняет 62,0% дисперсии
в данных, следующий основной компонент PC2 объясняет 24,7% дисперсиии, и тд. Что означает, что рассматривать PC3, PC4 и прочие не рационально тк они(в сумме) объясняют менее 20% общей дисперсии данных.

